{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy, Precision, Recall, MeanIoU\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['unlabeled', 0, 0, 0], ['paved-area', 128, 64, 128], ['dirt', 130, 76, 0], ['grass', 0, 102, 0], ['gravel', 112, 103, 87], ['water', 28, 42, 168], ['rocks', 48, 41, 30], ['pool', 0, 50, 89], ['vegetation', 107, 142, 35], ['roof', 70, 70, 70], ['wall', 102, 102, 156], ['window', 254, 228, 12], ['door', 254, 148, 12], ['fence', 190, 153, 153], ['fence-pole', 153, 153, 153], ['person', 255, 22, 96], ['dog', 102, 51, 0], ['car', 9, 143, 150], ['bicycle', 119, 11, 32], ['tree', 51, 51, 0], ['bald-tree', 190, 250, 190], ['ar-marker', 112, 150, 146], ['obstacle', 2, 135, 115], ['conflicting', 255, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the dataset (RGB images and class labels with RGB values)\n",
    "\n",
    "# Load RGB images\n",
    "rgb_images_dir = \"/home/don/Git/aerial-semantic-segmentation/dataset_here/dataset/semantic_drone_dataset/original_images\"\n",
    "rgb_images = []\n",
    "rgb_images_names = []\n",
    "# Load RGB images\n",
    "for image_name in sorted(os.listdir(rgb_images_dir)):\n",
    "    image_path = os.path.join(rgb_images_dir, image_name)\n",
    "    if image_name.lower().endswith('.jpg') or image_name.lower().endswith('.jpeg'):\n",
    "        label = os.path.splitext(image_name)[0]\n",
    "        rgb_images.append(image_path)\n",
    "        rgb_images_names.append(label)\n",
    "\n",
    "# Load class labels from CSV\n",
    "# class_labels_df = pd.read_csv(\"/home/don/Git/aerial-semantic-segmentation/dataset_here/class_dict_seg.csv\")\n",
    "labels = pd.read_csv('/home/don/Git/aerial-semantic-segmentation/dataset_here/class_dict_seg.csv')\n",
    "# convert to to list so each channel can be accessed\n",
    "labels = labels.values.tolist()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m class_labels \u001b[39m=\u001b[39m labels\n\u001b[1;32m      3\u001b[0m \u001b[39m# Step 2: Prepare the data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Split the class labels into separate color channels\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m red_channel \u001b[39m=\u001b[39m class_labels[:, \u001b[39m0\u001b[39;49m]\n\u001b[1;32m      6\u001b[0m green_channel \u001b[39m=\u001b[39m class_labels[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m blue_channel \u001b[39m=\u001b[39m class_labels[:, \u001b[39m2\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "class_labels = labels\n",
    "\n",
    "# Step 2: Prepare the data\n",
    "# Split the class labels into separate color channels\n",
    "red_channel = class_labels[:, 0]\n",
    "green_channel = class_labels[:, 1]\n",
    "blue_channel = class_labels[:, 2]\n",
    "# Combine the class labels into a single categorical label\n",
    "combined_labels = red_channel + 256 * green_channel + 256 * 256 * blue_channel\n",
    "# Apply one-hot encoding to convert categorical labels to binary vectors\n",
    "encoder = LabelEncoder()\n",
    "categorical_labels = keras.utils.to_categorical(encoder.fit_transform(combined_labels.ravel()))\n",
    "\n",
    "# Step 3: Split the data into train and test sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(rgb_images, categorical_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create a U-Net model\n",
    "def unet_model():\n",
    "    num_channels = 3\n",
    "    num_classes = categorical_labels.shape[1]\n",
    "    \n",
    "    # Define the U-Net architecture\n",
    "    inputs = Input((256, 256, num_channels))\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # Decoder\n",
    "    conv9 = Conv2D(num_classes, 1, activation='softmax')(pool1)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=conv9)\n",
    "    return model\n",
    "\n",
    "# Create an instance of the U-Net model\n",
    "unet_model = unet_model()\n",
    "\n",
    "# Step 5: Compile the model\n",
    "unet_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[Accuracy(), Precision(), Recall(), MeanIoU(num_classes=num_classes)])\n",
    "\n",
    "# Step 6: Train the model\n",
    "unet_model.fit(train_images, train_labels, batch_size=16, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "evaluation = unet_model.evaluate(test_images, test_labels)\n",
    "print(\"Evaluation loss:\", evaluation[0])\n",
    "print(\"Accuracy:\", evaluation[1])\n",
    "print(\"Precision:\", evaluation[2])\n",
    "print(\"Recall:\", evaluation[3])\n",
    "print(\"Mean IoU:\", evaluation[4])\n",
    "\n",
    "# Step 8: Make predictions\n",
    "predictions = unet_model.predict(test_images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
